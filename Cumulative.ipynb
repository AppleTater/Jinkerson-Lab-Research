{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cumulative",
      "provenance": [],
      "collapsed_sections": [
        "g4fSvasvNasY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AppleTater/Jinkerson-Lab-Research/blob/master/Cumulative.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PMzurW8anTY"
      },
      "source": [
        "# Files that need to be uploaded\n",
        "\n",
        "\n",
        "---\n",
        "* TAGData.csv\n",
        "* large-lib_full_2016.10.25.csv\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4fSvasvNasY"
      },
      "source": [
        "# Importing Libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtvJ3gtHFRzi"
      },
      "source": [
        "**Python Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3_bkIj1jNbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34bdb4d5-1d7e-40b7-e758-bf731c87e9a6"
      },
      "source": [
        "import pandas as pd                                       # importing common pandas libraries under the abbreviation 'pd' \n",
        "import matplotlib.pyplot as plt                           # was for the requested histogram under the abbreviation 'plt' \n",
        "\n",
        "import numpy.matlib                                       # to calculate mean and median\n",
        "import numpy as np                                        # numpy under the abbreviation 'np' \n",
        "from numpy import median                                  # from the numpy library, import how to get the median\n",
        "\n",
        "import scipy.stats as stats                               # libraries used for BH adjustment under the abbreviation 'stats' \n",
        "import scipy.special                                      # special libraries from scipy\n",
        "\n",
        "import re                                                 # more libraries\n",
        "import sys                                                # more libraries\n",
        "\n",
        "from IPython.display import (                             # display data, if wanted, as different media file types\n",
        "    display_pretty, display_html, display_jpeg,\n",
        "    display_png, display_json, display_latex, display_svg\n",
        ")\n",
        "\n",
        "from IPython.display import display                       # more display tools\n",
        "import itertools                                          # more display tools\n",
        "import gc                                                 # more display tools\n",
        "\n",
        "import statsmodels.api as sm                              # stats models under the abbreviation 'sm'\n",
        "import statsmodels.stats.multitest as smm                 # stats models under the abbreviation 'smm'\n",
        "import statsmodels.formula.api as smf                     # stats models under the abbreviation 'smf'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM0ZLceUFZGj"
      },
      "source": [
        "**R Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeFCVyiujV8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d20c6f6-5fa5-413a-cd07-054427001f46"
      },
      "source": [
        "%reload_ext rpy2.ipython\n",
        "\n",
        "# %%R\n",
        "# library(ggplot2)\n",
        "\n",
        "import rpy2.robjects as robjects                          # common rpy2 objects under the abbreviation 'robjects'\n",
        "from rpy2.robjects.packages import importr                # rpy2 packages under the abbreviation 'importr'\n",
        "from rpy2.robjects.vectors import FloatVector             # rpy2 for float conversion\n",
        "import gc                                                 # rpy2 library\n",
        "R_stats = importr('stats')                                # rpy2 stats\n",
        "\n",
        "from rpy2.rinterface_lib.sexp import StrSexpVector        # rpy2 interface\n",
        "from functools import partial                             # rpy2 tools under the abbreviation 'partial'\n",
        "from rpy2.ipython import html                             # html support\n",
        "html.html_rdataframe=partial(html.html_rdataframe, table_class=\"docutils\")\n",
        "\n",
        "from rpy2.robjects.conversion import localconverter       # rpy2 converter under the abbreviation 'localconverter'  \n",
        "\n",
        "import pandas as pd                                       # these libraries are for redundancy\n",
        "import rpy2.robjects as ro                                # ↓\n",
        "from rpy2.robjects.packages import importr                # ↓\n",
        "from rpy2.robjects import pandas2ri                       # ↓"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/rpy2/robjects/pandas2ri.py:14: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
            "  from pandas.core.index import Index as PandasIndex\n",
            "/usr/local/lib/python3.6/dist-packages/rpy2/robjects/pandas2ri.py:34: UserWarning: pandas >= 1.0 is not supported.\n",
            "  warnings.warn('pandas >= 1.0 is not supported.')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3OvwxcvOZkW"
      },
      "source": [
        "# Making of the Merged File\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNIt7fXu0jEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670e7b21-1acf-4eb1-b6e4-1aa68a622463"
      },
      "source": [
        "data_df = pd.read_csv('TAG Data.csv')                           # read TAG Data.csv file, read in as 'data'\n",
        "\n",
        "data_df = data_df[['gene' , 'R5-S#11-HLG_WHOLE_normalized_reads' , 'R5-S#11-ALL_WHOLE_normalized_reads']]       \n",
        "      # create dataframe from the TAG Data using the included columns\n",
        "data_df ['Ratios: HLG / ALL (Whole)'] = data_df ['R5-S#11-HLG_WHOLE_normalized_reads'] / data_df['R5-S#11-ALL_WHOLE_normalized_reads']       \n",
        "      # create another column for the ratio, high lipid gate vs all\n",
        "\n",
        "data_df = data_df.sort_values('gene')                           # sort 'data' by the gene names, alphabetically (numerically in this case)\n",
        "data_df = data_df.replace([np.inf, -np.inf], np.nan)            # replace gene names that are 'np.inf' or '-np.inf' to 'np.nan'\n",
        "data_df = data_df.dropna()                                      # drop all rows that have 'np.nan' which we coverted in the step above\n",
        "\n",
        "data_df = data_df.drop(['R5-S#11-HLG_WHOLE_normalized_reads' , 'R5-S#11-ALL_WHOLE_normalized_reads'], axis = 1)\n",
        "      # drop these columns because the only use for them was to create the ratio, so they are no longer needed\n",
        "\n",
        "data_df = pd.DataFrame(data_df)\n",
        "      # consolidate all changes made to 'data' to a dataframe\n",
        "\n",
        "mean_df = data_df.groupby(['gene']).mean()                      # calculate the mean as an independent dataframe\n",
        "mean_df.rename(columns = {'Ratios: HLG / ALL (Whole)': 'Ratio Mean'}, inplace = True)\n",
        "      # rename column for better readbility\n",
        "\n",
        "median_df = data_df.groupby(['gene']).median()                  # find the median as an independent dataframe\n",
        "median_df.rename(columns = {'Ratios: HLG / ALL (Whole)': 'Ratio Median'}, inplace = True)\n",
        "      # rename column for better readbility\n",
        "\n",
        "count_df = data_df.groupby(['gene']).count()                    # total number of counts per gene as an independent dataframe\n",
        "count_df.rename(columns = {'Ratios: HLG / ALL (Whole)': 'Count'}, inplace = True)\n",
        "      # rename column for better readbility\n",
        "\n",
        "result_df = data_df.reset_index(drop = True)                    # reset the index of the dataframe\n",
        "result_df = pd.concat([mean_df, median_df, count_df], axis = 1)       \n",
        "      # concatenate the independent dataframes of 'mean', 'median', and 'count' as one large dataframe\n",
        "\n",
        "result_df = result_df.sort_values(by = ['Ratio Median'], ascending = False)\n",
        "      # sort the concatenated dataframe by the median (greatest ⟶ least)\n",
        "\n",
        "counter = float(input(\"Enter the count number that you want results that are less than to be cut off at: \")) \n",
        "      # asking user for input, stored as 'counter'\n",
        "      # asking for a cutoff of the total number of counts for a gene\n",
        "greater = result_df[result_df['Count'] < counter].index\n",
        "      # independent dataframe from 'counter', where if the column 'Count' is less than the 'counter', it will be stored in 'greater'\n",
        "\n",
        "result_df.drop(greater, inplace = True)\n",
        "      # remove 'greater' from the concateneated dataframe that is sorted by the median value\n",
        "result_df.reset_index(inplace = True)                           # reset the index of the dataframe\n",
        "\n",
        "groupby = result_df.rename(columns = {'gene' : \"Gene\"})\n",
        "      # new dataframe, using data from the dropped 'greater' and rename the column 'gene' to 'Gene'\n",
        "\n",
        "data_lib = pd.read_csv('large-lib_full_2016.10.25.csv')\n",
        "      # read in data from large-lib_full_2016.10.25.csv, stored in 'data_lib'\n",
        "\n",
        "data_lib = data_lib.drop(['well', 'side', 'chromosome', 'plate', 'strand', \n",
        "                  'min_position', 'full_position', 'orientation', \n",
        "                  'gene_end_distances', 'total_reads', \n",
        "                  'if_both_sides', 'LEAPseq_distance', \n",
        "                  'LEAPseq_percent_confirming',\n",
        "                  'LEAPseq_N_confirming', 'LEAPseq_N_nonconf', \n",
        "                  'LEAPseq_N_unique_pos',\n",
        "                  'flanking_seq', 'plate_errors', 'well_errors', \n",
        "                  'plate_rpm', 'well_rpm',\n",
        "                  'if_fixed_position'], axis = 1)\n",
        "      # drop all ↑ columns from data_lib\n",
        "\n",
        "level = float(input(\"Enter the confidence level that you want the data to be less than or equal to (1 - 5): \"))\n",
        "      # asking for user input, only accepting numerical values, for the confindence level that you want the resulting data to be less than or equal to, stored in 'level'\n",
        "filter_data_lib = data_lib[data_lib['confidence_level'] <= level]\n",
        "      # begin to filter data, using 'level' store the genes that are less than or equal to the confindence level entered for 'level' in 'filter_data_lib'\n",
        "filter_data_lib = filter_data_lib.sort_values('confidence_level')\n",
        "      # sort filter_data_lib by their confidence levels (least ⟶ greatest)\n",
        "filter_data_lib = filter_data_lib.rename(columns = {\"gene\" : \"Gene\",\n",
        "                                          \"confidence_level\" : \"Confidence Level\",\n",
        "                                          \"feature\" : \"Feature\"})\n",
        "      # rename columns: 'gene' to 'Gene', 'confidence_level' to \"Confidence Level\", and 'feature' to \"Feature\" \n",
        "filter_data_lib = filter_data_lib.reset_index(drop = True)\n",
        "      # reset index, and drop old index\n",
        "\n",
        "gene_name = filter_data_lib[\"Gene\"].astype(str).str.replace(r'.v5.5$', '')\n",
        "      # convert data type of column Gene to a string and replace '.v5.5$' with a whitespace\n",
        "gene_name = gene_name.str.replace(r\".v5.5\", '').str.strip()\n",
        "      # remove '.v5.5$'\n",
        "\n",
        "filter_data_lib = filter_data_lib.drop(columns = {\"Gene\"})\n",
        "      # drop Gene column\n",
        "filter_data_lib[\"Gene\"] = gene_name \n",
        "      # replace Gene Column by data where we removed '.v5.5$'\n",
        "\n",
        "filter_data_lib =  filter_data_lib[[\"Gene\", \"Confidence Level\", \"IB\", \"Feature\"]]\n",
        "      # filter data, so that only columns Gene, Confidence Level, IB, and Feature remain and is stored into 'filter_data_lib'\n",
        "\n",
        "df1 = groupby\n",
        "      # dataframe1 (df1) is holding data from groupby, see above ↑\n",
        "\n",
        "df3 = filter_data_lib\n",
        "      # dataframe3 (df3) is holding data from filter_data_lib, see above ↑\n",
        "\n",
        "leftBigMerge = pd.merge(left = df1, right = df3, how = 'left', \n",
        "                        left_on = 'Gene', right_on = 'Gene')\n",
        "      # Merge both df1 and df3 to be one dataframe, aligned by gene names, named 'leftBigMerge'\n",
        "      # the 'left' stuff is just so that we don't lose any data when merging, and just in case some data is double counted \n",
        "      # take it like a common factor, but the commonality (gene name) is on the left of the dataframe\n",
        "\n",
        "leftBigMerge = leftBigMerge[[\"Gene\", \"Ratio Median\", \"Ratio Mean\", \n",
        "                             \"Feature\", \"Confidence Level\", \"IB\"]]\n",
        "      # leftBigMerge only to keep columns: Gene, Ratio Median, Ratio Mean, Feature, Confidence Level, and IB\n",
        "\n",
        "# Now the data that we need from 2 dataframes has been consolidated into 1 dataframe, sorted by gene name, organized by ratio median"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the count number that you want results that are less than to be cut off at: 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Enter the confidence level that you want the data to be less than or equal to (1 - 5): 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdpANp4qaKu4"
      },
      "source": [
        "# Fisher Exact\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp8rwVItPvLQ"
      },
      "source": [
        "**Fisher Exact Test Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1gcMa3vOik3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a7ebab8-fedb-43ac-cd0a-534a7bed0f35"
      },
      "source": [
        "matrix = leftBigMerge                                           # set 'matrix' to be 'leftBigMerge'\n",
        "\n",
        "matrix_to_df = pd.DataFrame(matrix, columns = [\"Gene\", \"Ratio Median\",\n",
        "                                          \"Ratio Mean\",\n",
        "                                          \"Description\"])\n",
        "      # create another dataframe, named 'matrix_to_df' from data from 'matrix', taking on the columns listed\n",
        "matrix_to_df = matrix_to_df.drop_duplicates()\n",
        "      # drop duplicates from 'matrix_to_df'\n",
        "\n",
        "data = pd.read_csv('TAG Data.csv')\n",
        "      # read in 'TAG Data.csv' and store the data in 'data'\n",
        "\n",
        "data = data[['IB' , 'gene' , 'R5-S#11-HLG_WHOLE_normalized_reads' , 'R5-S#11-ALL_WHOLE_normalized_reads']]\n",
        "      # have data only contain these columns from 'TAG Data.csv'\n",
        "data ['Ratios: HLG / ALL (Whole)'] = data ['R5-S#11-HLG_WHOLE_normalized_reads'] / data['R5-S#11-ALL_WHOLE_normalized_reads']\n",
        "      # create another column for the ratio, high lipid gate vs all\n",
        "\n",
        "data = data.sort_values('gene')                                 # sort 'data' by the gene names, alphabetically (numerically in this case)\n",
        "data = data.replace([np.inf, -np.inf], np.nan)                  # replace gene names that are 'np.inf' or '-np.inf' to 'np.nan'\n",
        "data = data.dropna()                                            # drop all rows that have 'np.nan' which we coverted in the step above\n",
        "data = data.drop(columns = {\"R5-S#11-HLG_WHOLE_normalized_reads\", \"R5-S#11-ALL_WHOLE_normalized_reads\"})\n",
        "      # drop these columns because the only use for them was to create the ratio, so they are no longer needed\n",
        "\n",
        "ratio = float(input(\"Enter value that you want data to be greater than (Ratio: HLG / ALL (Whole)): \"))\n",
        "      # requesting user input, stored as 'ratio', need to enter a float\n",
        "      # asking for the value of ratio you want the remaining data to be greater than\n",
        "data[\"RatioType\"] = np.where(data[\"Ratios: HLG / ALL (Whole)\"] > ratio, \"Hit\", \"Non-Hit\")\n",
        "      # new column in 'data', entitled, \"RatioType\", where the ratio is greater than the ratio is greater than what was just entered\n",
        "data = data.sort_values(\"gene\")                                 # sort 'data' by the gene names, alphabetically (numerically in this case)\n",
        "data = data.reset_index(drop = True)                            # reset the index\n",
        "data = data.replace(['unknown_chrom', 'no_gene_found',   \n",
        "                     'gene_unknown'], np.nan)\n",
        "      # replace values that are 'unknown_chrom', 'no_gene_found', or 'gene_unknown' to NaN\n",
        "data = data.dropna()\n",
        "      # drop all NaN values\n",
        "\n",
        "unknown = data[data.gene.eq(\"unknown_chrom\") |\n",
        "               data.gene.eq(\"no_gene_found\") |\n",
        "               data.gene.eq(\"gene_unknown\")]\n",
        "      # create a dataframe where the gene name is 'unknown_chrom', 'no_gene_found', or 'gene_unknown'\n",
        "      # what we previously dropped\n",
        "\n",
        "unknown = unknown.reset_index(drop = True)\n",
        "      # reset the index of 'unknown'\n",
        "\n",
        "for gene, data_gene in data.groupby('gene'):\n",
        "    data_gene\n",
        "      # consolidates data to its IB, gene name, the ratio, and the ratio type\n",
        "      # runs in a loop until entire dataframe has been searched     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter value that you want data to be greater than (Ratio: HLG / ALL (Whole)): 0.15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn9r9qHiVmbu"
      },
      "source": [
        "**Actual Fisher Exact Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlmSjxKXQD77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2914a36f-fcb6-41e3-ba41-e919bd36904b"
      },
      "source": [
        "overall_hit = 0                                                 # initialize a variable, 'overall_hit' and set to 0\n",
        "overall_not_hit = 0                                             # initialize a varaible, 'overall_not_hit' and set to 0\n",
        "\n",
        "lastGene = data_gene['gene'].iloc[-1]                           # get the very last gene and its information from data_gene, stored as 'lastGene'\n",
        "count = float(input(\"For the total number of counts (hits + non-hits) of a gene, enter a number for cutoff : \"))\n",
        "      # ask user for input, stored as floating 'count'\n",
        "      # asking for the cutoff for genes that have a count that is less than 'count'\n",
        "\n",
        "for gene, data_genie in data.groupby('gene'):                   # starting of a loop, that will run and increment until the end of 'data'\n",
        "    data_genie = data_genie.drop(columns = {'IB', \"Ratios: HLG / ALL (Whole)\"})\n",
        "      # 'data_genie' is a dataframe that takes in every gene, one by one, per increment, and only keeps gene name, and ratio type \n",
        "   \n",
        "    hit = data_genie.loc[data_genie.RatioType == 'Hit', \"RatioType\"].count()\n",
        "      # hit is a dataframe that holds the genes with the ratio type, \"Hit\", and counts it\n",
        "    noHit = data_genie.loc[data_genie.RatioType == \"Non-Hit\", \"RatioType\"].count()\n",
        "      # noHit is a dataframe that holds the genes with the ratio type, \"Non-Hit\", and counts it\n",
        "\n",
        "    overall_hit =  overall_hit + hit                           # count the number of hits, adding overall_hit on top of overall_hit, which is why overall_hit was initialized outside of the loop\n",
        "    overall_not_hit = overall_not_hit + noHit                  # count the number of non-hits, adding overall_not_hit on top of overall_not_hit, which is why overall_not_hit was initialized outside of the loop\n",
        "\n",
        "    if lastGene in data_genie.values:                          # if the lastGene is the current iteration, the loop ends, else, the current gene is not the lastGene, the loop continues to run\n",
        "        sum = pd.DataFrame (                                   # dataframe, 'sum', stores the total number of hits and total number of non-hits\n",
        "            { \n",
        "                'Hit' : overall_hit,                           # make a column, in 'sum', 'Hit' with the data from overall_hit \n",
        "                'Non-Hit' : overall_not_hit                    # make a column, in 'sum', 'Non-Hit' with the data from overall_not_hit\n",
        "            }, index = [0]                                \n",
        "        )                                                      # end of if statement\n",
        "\n",
        "# end of first for loop, now we have a dataframe with just the gene name (with their corresponsding ratio type), and the total number of hits and non-hits of all genes\n",
        "\n",
        "df_drop = pd.DataFrame()                                       # initialize empty dataframe, 'df_drop'\n",
        "overall_df_drop = pd.DataFrame()                               # initialize empty dataframe, 'overall_df_drop'\n",
        "\n",
        "df_drop_name = pd.DataFrame()                                  # initialize empty dataframe, 'df_drop_name'\n",
        "overall_df_drop_name = pd.DataFrame()                          # initialize empty dataframe, 'overall_df_drop_name'\n",
        "\n",
        "for gene, data_genie in data.groupby('gene'):                  # second for loop, will run and increment until the end of 'data'\n",
        "    data_genie = data_genie.drop(columns = {'IB', \"Ratios: HLG / ALL (Whole)\"})\n",
        "      # 'data_genie' is a dataframe that takes in every gene, one by one, per increment, and only keeps gene name, and ratio type\n",
        "   \n",
        "    hit = data_genie.loc[data_genie.RatioType == 'Hit', \"RatioType\"].count()\n",
        "      # hit is a dataframe that holds the genes with the ratio type, \"Hit\", and counts it\n",
        "    noHit = data_genie.loc[data_genie.RatioType == \"Non-Hit\", \"RatioType\"].count()\n",
        "      # noHit is a dataframe that holds the genes with the ratio type, \"Non-Hit\", and counts it\n",
        "    \n",
        "    overall_hit =  overall_hit + hit                          # count the number of hits, adding overall_hit on top of overall_hit, which is why overall_hit was initialized outside of the loop\n",
        "    overall_not_hit = overall_not_hit + noHit                 # count the number of non-hits, adding overall_not_hit on top of overall_not_hit, which is why overall_not_hit was initialized outside of the loop\n",
        "    \n",
        "    u_gene = pd.DataFrame (                                   # create a new dataframe, 'u_gene', with one column, 'Gene', storing each unique gene\n",
        "        {\n",
        "        'Gene': data_genie.gene.unique()\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    hitting = pd.DataFrame (                                  # create a new dataframe, 'hitting', for each gene and their hits and non-hits\n",
        "         {\n",
        "            'Hit' : hit,\n",
        "            'Non-Hit' : noHit\n",
        "        }, index = [0]\n",
        "    )\n",
        "\n",
        "    concat = pd.concat([hitting, sum], ignore_index = True)  # concatenate the dataframes 'hitting' and 'sum' (individual gene hits and non-hits vs. total gene hits and non-hits) to 'concat'\n",
        "    concat = concat.to_numpy()                               # convert 'concat' to all numpy values\n",
        "    \n",
        "    df_to_numpy = np.array(concat)                                   # 'df_to_numpy' takes on 'concat' as an array of numpy values instead of a dataframe\n",
        "    new = pd.DataFrame(df_to_numpy)                                  # 'new' takes on 'df_to_numpy' as a dataframe\n",
        "\n",
        "# beginning of the Fisher Exact Test, everything up until now was in preparation\n",
        "    oddsratio, fisher = stats.fisher_exact(new)              # performs Fisher Exact Test on a 2 x 2 contingency table\n",
        "        # contingency table:                                 # store the p-values as 'fisher'\n",
        "        # |        |   Hit   |   Non-Hit   |\n",
        "        # |————————|—————————|—————————————|  \n",
        "        # |  gene  |         |             | ← (this is from 'hitting')\n",
        "        # |————————|—————————|—————————————|  \n",
        "        # |  total |         |             | ← (this is from 'sum')\n",
        "        # this is what was concatenated a few lines above\n",
        "    \n",
        "    fisher_array = np.asarray(fisher)                        # convert 'fisher' to an array, stored as 'fisher_array' \n",
        "    fisher_array = fisher_array.reshape(-1, 1)                            \n",
        "        # reshape p-values in 'fisher_array' to be their own arrays:\n",
        "        # array ([[p-value of the first gene],\n",
        "        #         [p-value of the second gene],\n",
        "        #         [p-value of the third gene], \n",
        "        #         etc.])                           \n",
        "\n",
        "    hitting.astype(float)                                   # ensure that 'hitting' stores floats\n",
        "    sum.astype(float)                                       # ensure that 'sum' stores floats\n",
        "\n",
        "    p_val = pd.DataFrame(data = fisher_array, columns = [\"p-value\"])\n",
        "        # 'p_val' is a dataframe storing the data from 'fisher_array' under column \"p-values\"\n",
        "    p_val.astype(float)                                       # make sure 'p_val' stores floats\n",
        "    \n",
        "    matrix_to_df = np.concatenate((hitting, sum), axis = 0)   # concatenate 'hitting' and 'sum', store as 'matrix_to_df'\n",
        "    matrix_to_df = pd.DataFrame(data = matrix_to_df, columns = [\"Hit\", \"Non-Hit\"])\n",
        "        # for the data in 'matrix_to_df', title the two columns \"Hit\" and \"Non-Hit\"\n",
        "    p_val_again = pd.DataFrame(data = p_val, columns = [\"p-value\"])\n",
        "        # data in 'p_val' is the p-values, stored as a dataframe, 'p_val_again'\n",
        "\n",
        "        # ↓ if I recall correctly, this is what is made for every gene ↓\n",
        "        # | Gene Name                      |\n",
        "        # |————————————————————————————————|\n",
        "        # |        |   Hit   |   Non-Hit   |\n",
        "        # |————————|—————————|—————————————|\n",
        "        # |  gene  |         |             |\n",
        "        # |————————|—————————|—————————————|  \n",
        "        # |  total |         |             |\n",
        "        # |————————————————————————————————|\n",
        "        # |        |         |   p-value   |\n",
        "\n",
        "    p_and_matrix = pd.concat([matrix_to_df, p_val_again], ignore_index = True, sort = True)\n",
        "        # concatenate 'matrix_to_df' and 'p_val_again', stored as 'p_and_matrix'\n",
        "    p_and_matrix = pd.concat([u_gene, p_and_matrix], axis = 1)\n",
        "        # update 'p_and_matrix' by storing the concatenation of 'u_gene' (which was the unique gene names) \n",
        "        # and 'p_and_matrix' (from the step above, is the concatenation of 'matrix_to_df' and 'p_val_again')\n",
        "\n",
        "    p_and_matrix.loc[p_and_matrix['Hit'] + p_and_matrix['Non-Hit'] < count] = \"Go Away\"\n",
        "        # taking the user input, from the beginning of the cell, asking for the count that you want \n",
        "        # the remaining data to be greater than, from 'p_and_matrix', replace the values \n",
        "        # in the gene name column with \"Go Away\"\n",
        "\n",
        "    if p_and_matrix.iloc[0, 0] == \"Go Away\":                       # if the gene name is exactly \"Go Away\"\n",
        "      p_and_matrix.iloc[2, 3] = \"NO\"                               # then \"NO\" is stored in the p-value's cell of the dataframe\n",
        "\n",
        "    df_drop = p_and_matrix.iloc[2]                                  # 'df_drop' stores the data from 'p_and_matrix' if it is \"Go Away\"    \n",
        "    overall_df_drop = overall_df_drop.append(df_drop)               # 'overall_df_drop' is used to append 'goway' to each other \n",
        "\n",
        "    df_drop_name = p_and_matrix.iloc[0]                             # 'df_drop_name' stores names from 'p_and_matrix'\n",
        "    overall_df_drop_name = overall_df_drop_name.append(df_drop_name)   # 'overall_df_drop_name' is used to append 'drop_name' to each other\n",
        "\n",
        "# this all happens in a for loop, so the resulting dataframes are larger and larger\n",
        "# please forgive the long run time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For the total number of counts (hits + non-hits) of a gene, enter a number for cutoff : 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4eeDbGBVcEl"
      },
      "source": [
        "# taking the last dataframe from the last iteration of the for-loop in the previous cell:\n",
        "final_p_vals = overall_df_drop.drop(columns = [\"Gene\", \"Hit\", \"Non-Hit\"]) \n",
        "      # 'final_p_vals' stores the data from 'overall_df_drop', dropping the \"Gene\", \"Hit\", and \"Non-Hit\" columns\n",
        "      # only \"p-values\" remains\n",
        "final_p_vals = final_p_vals[final_p_vals[\"p-value\"] != \"NO\"]\n",
        "      # 'final_p_vals' is updated as it checks all the values in \"p-value\", keeping only those that are not \"NO\"\n",
        "final_p_vals = final_p_vals.reset_index(drop = True)\n",
        "      # reset the index of 'final_p_vals'\n",
        "\n",
        "final_names = overall_df_drop_name.drop(columns = [\"Hit\", \"Non-Hit\", \"p-value\"])\n",
        "      # 'final_names' stores the data from 'overall_df_drop_name', dropping the \"Hit\", \"Non-Hit\", and \"p-value\" columns\n",
        "      # only \"Gene\" remains\n",
        "final_names = final_names[final_names[\"Gene\"] != \"Go Away\"]\n",
        "      # 'final_names' is updated as it checks all the values in \"Gene\", keeping only those that are not \"Go Away\"\n",
        "final_names = final_names.reset_index(drop = True)\n",
        "      # reset the index of final_names\n",
        "\n",
        "merge_final_name = final_names.merge(final_p_vals, left_index = True, right_index = True)\n",
        "      # merge 'final_names' and 'final_p_vals' by the gene name, stored as 'merge_final_name'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rez3QbLQBXE"
      },
      "source": [
        "#Benjamini-Hochberg Adjustment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLeKkaSVVwsF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "1fbba105-d3c4-40c5-d29a-9b62f9dc6023"
      },
      "source": [
        "before_p_adj = merge_final_name[~merge_final_name.Gene.str.contains(\" & \")]\n",
        "      # drop any rows in 'merge_final_name' with values in the \"Gene\" column that contain \" & \"\n",
        "      # store the remaining rows in 'before_p_adj'\n",
        "before_p_adj = before_p_adj.reset_index(drop = True)                # reset the index of 'before_p_adj'\n",
        "\n",
        "bh_num = float(input(\"Enter the value that all adjusted p-values should be less than (0-1): \"))\n",
        "      # user input, asking for the maximum of the adjusted p-value, store as 'bh_num'\n",
        "\n",
        "# ↓ Benjamini-Hochberg Adjustment of p-values ↓\n",
        "# calls on a statisical adjustment from an R library: \n",
        "def FDR_adjust_pvalues(case, N=None, method='BH'):\n",
        "    \"\"\" Adjust a list of p-values for false discovery rate using R's stats::p.adjust function.\n",
        "\n",
        "    N and method are passed to R_stats.p_adjust:\n",
        "     - N is the number of comparisons (if left unspecified, defaults to len(pvalue_list), I think)\n",
        "     - method is the name of the adjustment method to use (inherited from R)\n",
        "\n",
        "    Note that this MUST be done after all the p-values are already collected, on the full list of p-values at once:\n",
        "     trying to do it on single p-values, even with adjusted N, will give different results!\n",
        "    \"\"\"\n",
        "    if not method in R_stats.p_adjust_methods:\n",
        "        raise ValueError(\"Unknown method %s - method must be one of (%s)!\"%(method, ', '.join(R_stats.p_adjust_methods)))\n",
        "    if N is None:   return R_stats.p_adjust(FloatVector(case), method=method)\n",
        "    else:           return R_stats.p_adjust(FloatVector(case), method=method, n=N)\n",
        "\n",
        "before_p_adj[\"Adjusted p-value\"] = FDR_adjust_pvalues(before_p_adj['p-value'])\n",
        "      # make a new column in 'before_p_adj', \"Adjusted p-value\"\n",
        "      # using False Discovery Rates (FDR) / correction on the adjusted p-values\n",
        "\n",
        "before_p_adj.sort_values(by = 'p-value')\n",
        "      # sort 'before_p_adj' by their p-values\n",
        "\n",
        "adjusted_p = before_p_adj.loc[before_p_adj[\"Adjusted p-value\"] < bh_num]\n",
        "      # keeps the rows with adjusted p-values that are less than 'bh_num', stored as dataframe 'adjusted_p'\n",
        "\n",
        "display(adjusted_p)                                             # display 'adjusted_p' as a dataframe\n",
        "\n",
        "# conclusion: total time to run all cells 8 - 10 minutes\n",
        "# majority of the time is taken by the \"Actual Fisher Test\" cell"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the value that all adjusted p-values should be less than (0-1): 0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gene</th>\n",
              "      <th>p-value</th>\n",
              "      <th>Adjusted p-value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5237</th>\n",
              "      <td>Cre07.g330200</td>\n",
              "      <td>4.63258e-05</td>\n",
              "      <td>0.287961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9846</th>\n",
              "      <td>Cre13.g584901</td>\n",
              "      <td>1.18433e-05</td>\n",
              "      <td>0.147236</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Gene      p-value  Adjusted p-value\n",
              "5237  Cre07.g330200  4.63258e-05          0.287961\n",
              "9846  Cre13.g584901  1.18433e-05          0.147236"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}