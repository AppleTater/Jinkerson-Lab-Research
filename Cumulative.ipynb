{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cumulative",
      "provenance": [],
      "collapsed_sections": [
        "g4fSvasvNasY",
        "Z3OvwxcvOZkW",
        "qdpANp4qaKu4",
        "4rez3QbLQBXE"
      ],
      "authorship_tag": "ABX9TyOrvBnegYtC6rKdzYlF2Qj5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AppleTater/Jinkerson-Lab-Research/blob/master/Cumulative.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PMzurW8anTY"
      },
      "source": [
        "# Files that need to be uploaded\n",
        "\n",
        "\n",
        "---\n",
        "* TAGData.csv\n",
        "* large-lib_full_2016.10.25.csv\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4fSvasvNasY"
      },
      "source": [
        "# Importing Libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtvJ3gtHFRzi"
      },
      "source": [
        "**Python Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3_bkIj1jNbi"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy.matlib\n",
        "import numpy as np\n",
        "from numpy import median\n",
        "\n",
        "import scipy.stats as stats\n",
        "import scipy.special\n",
        "\n",
        "import re\n",
        "import sys\n",
        "\n",
        "from IPython.display import (\n",
        "    display_pretty, display_html, display_jpeg,\n",
        "    display_png, display_json, display_latex, display_svg\n",
        ")\n",
        "\n",
        "from IPython.display import display\n",
        "import itertools\n",
        "import gc\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.stats.multitest as smm\n",
        "import statsmodels.formula.api as smf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM0ZLceUFZGj"
      },
      "source": [
        "**R Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeFCVyiujV8p"
      },
      "source": [
        "%reload_ext rpy2.ipython\n",
        "\n",
        "# %%R\n",
        "# library(ggplot2)\n",
        "\n",
        "import rpy2.robjects as robjects\n",
        "from rpy2.robjects.packages import importr\n",
        "from rpy2.robjects.vectors import FloatVector\n",
        "import gc\n",
        "R_stats = importr('stats')\n",
        "\n",
        "from rpy2.rinterface_lib.sexp import StrSexpVector\n",
        "from functools import partial\n",
        "from rpy2.ipython import html\n",
        "html.html_rdataframe=partial(html.html_rdataframe, table_class=\"docutils\")\n",
        "\n",
        "from rpy2.robjects.conversion import localconverter\n",
        "\n",
        "import pandas as pd\n",
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects.packages import importr\n",
        "from rpy2.robjects import pandas2ri\n",
        "\n",
        "from rpy2.robjects.conversion import localconverter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3OvwxcvOZkW"
      },
      "source": [
        "# Making of the Merged File\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNIt7fXu0jEg",
        "outputId": "270c8b9c-5123-4de0-a29c-cd47edf80c8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "data = pd.read_csv('TAG Data.csv')\n",
        "\n",
        "data = data[['gene' , 'R5-S#11-HLG_WHOLE_normalized_reads' , 'R5-S#11-ALL_WHOLE_normalized_reads']]\n",
        "data ['Ratios: HLG / ALL (Whole)'] = data ['R5-S#11-HLG_WHOLE_normalized_reads'] / data['R5-S#11-ALL_WHOLE_normalized_reads']\n",
        "\n",
        "data = data.sort_values('gene')\n",
        "data = data.replace([np.inf, -np.inf], np.nan)\n",
        "data = data.dropna()\n",
        "\n",
        "data = data.drop(['R5-S#11-HLG_WHOLE_normalized_reads' , 'R5-S#11-ALL_WHOLE_normalized_reads'], axis = 1)\n",
        "\n",
        "data = pd.DataFrame(data)\n",
        "\n",
        "mean = data.groupby(['gene']).mean()\n",
        "mean.rename(columns = {'Ratios: HLG / ALL (Whole)': 'Ratio Mean'}, inplace = True)\n",
        "# mean\n",
        "\n",
        "median = data.groupby(['gene']).median()\n",
        "median.rename(columns = {'Ratios: HLG / ALL (Whole)': 'Ratio Median'}, inplace = True)\n",
        "# median\n",
        "\n",
        "count = data.groupby(['gene']).count()\n",
        "count.rename(columns = {'Ratios: HLG / ALL (Whole)': 'Count'}, inplace = True)\n",
        "# count\n",
        "\n",
        "result = data.reset_index(drop = True)\n",
        "result = pd.concat([mean, median, count], axis = 1)\n",
        "\n",
        "result = result.sort_values(by = ['Ratio Median'], ascending = False)\n",
        "\n",
        "counter = float(input(\"Enter the count number that you want results that are less than to be cut off at: \"))\n",
        "greater = result[result['Count'] < counter].index\n",
        "\n",
        "result.drop(greater, inplace = True)\n",
        "result.reset_index(inplace = True)\n",
        "\n",
        "groupby = result.rename(columns = {'gene' : \"Gene\"})\n",
        "\n",
        "#Confidence Level\n",
        "ba = pd.read_csv('large-lib_full_2016.10.25.csv')\n",
        "\n",
        "ba = ba.drop(['well', 'side', 'chromosome', 'plate', 'strand', \n",
        "                  'min_position', 'full_position', 'orientation', \n",
        "                  'gene_end_distances', 'total_reads', \n",
        "                  'if_both_sides', 'LEAPseq_distance', \n",
        "                  'LEAPseq_percent_confirming',\n",
        "                  'LEAPseq_N_confirming', 'LEAPseq_N_nonconf', \n",
        "                  'LEAPseq_N_unique_pos',\n",
        "                  'flanking_seq', 'plate_errors', 'well_errors', \n",
        "                  'plate_rpm', 'well_rpm',\n",
        "                  'if_fixed_position'], axis = 1)\n",
        "\n",
        "level = float(input(\"Enter the confidence level that you want the data to be less than or equal to: \"))\n",
        "filterba = ba[ba['confidence_level'] <= level]\n",
        "filterba = filterba.sort_values('confidence_level')\n",
        "filterba = filterba.rename(columns = {\"gene\" : \"Gene\",\n",
        "                                          \"confidence_level\" : \"Confidence Level\",\n",
        "                                          \"feature\" : \"Feature\"})\n",
        "filterba = filterba.reset_index(drop = True)\n",
        "\n",
        "genie = filterba[\"Gene\"].astype(str).str.replace(r'.v5.5$', '')\n",
        "genie = genie.str.replace(r\".v5.5\", '').str.strip()\n",
        "\n",
        "filterba = filterba.drop(columns = {\"Gene\"})\n",
        "filterba[\"Gene\"] = genie\n",
        "\n",
        "filterba =  filterba[[\"Gene\", \"Confidence Level\", \"IB\", \"Feature\"]]\n",
        "\n",
        "#GO Term\n",
        "#gogo = pd.read_csv('GOTerms.csv')\n",
        "\n",
        "#Merging all 3\n",
        "df1 = groupby\n",
        "#df2 = gogo\n",
        "df3 = filterba\n",
        "\n",
        "leftBigMerge = pd.merge(left = df1, right = df3, how = 'left', \n",
        "                        left_on = 'Gene', right_on = 'Gene')\n",
        "#leftBigMerge = pd.merge(left = leftBigMerge, right = df3, how = 'left',\n",
        "                        #left_on = 'Gene', right_on = 'Gene')\n",
        "#leftBigMerge = leftBigMerge.drop(columns = [\"Unnamed: 0_x\", \"Unnamed: 0_y\", \n",
        "                                   # \"Unnamed: 0\"])\n",
        "leftBigMerge = leftBigMerge[[\"Gene\", \"Ratio Median\", \"Ratio Mean\", #\"GO Term\", \n",
        "                             \"Feature\", \"Confidence Level\", \"IB\"]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the count number that you want results that are less than to be cut off at: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Enter the confidence level that you want the data to be less than or equal to: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdpANp4qaKu4"
      },
      "source": [
        "# Fishing ðŸŸðŸ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp8rwVItPvLQ"
      },
      "source": [
        "**Fisher Exact Test Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1gcMa3vOik3",
        "outputId": "f846f63f-de0a-43cf-966c-a1c628045f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#matrix = df.to_numpy()\n",
        "matrix = leftBigMerge\n",
        "\n",
        "oarfish = pd.DataFrame(matrix, columns = [\"Gene\", \"Ratio Median\",\n",
        "                                          \"Ratio Mean\", #\"GO Term\",\n",
        "                                          \"Description\"])\n",
        "\n",
        "oarfish = oarfish.drop_duplicates()\n",
        "\n",
        "data = pd.read_csv('TAG Data.csv')\n",
        "\n",
        "data = data[['IB' , 'gene' , 'R5-S#11-HLG_WHOLE_normalized_reads' , 'R5-S#11-ALL_WHOLE_normalized_reads']]\n",
        "data ['Ratios: HLG / ALL (Whole)'] = data ['R5-S#11-HLG_WHOLE_normalized_reads'] / data['R5-S#11-ALL_WHOLE_normalized_reads']\n",
        "\n",
        "data = data.sort_values('gene')\n",
        "data = data.replace([np.inf, -np.inf], np.nan)\n",
        "data = data.dropna()\n",
        "data = data.drop(columns = {\"R5-S#11-HLG_WHOLE_normalized_reads\", \n",
        "                            \"R5-S#11-ALL_WHOLE_normalized_reads\"})\n",
        "\n",
        "ratio = float(input(\"Enter value that you want data to be greater than (Ratio: HLG / ALL (Whole)): \"))\n",
        "\n",
        "data[\"RatioType\"] = np.where(data[\"Ratios: HLG / ALL (Whole)\"] > ratio, \n",
        "                                 \"Hit\", \"Non-Hit\")\n",
        "data = data.sort_values(\"gene\")\n",
        "data = data.reset_index(drop = True)\n",
        "data = data.replace(['unknown_chrom', 'no_gene_found', \n",
        "                     'gene_unknown'], np.nan)\n",
        "data = data.dropna()\n",
        "\n",
        "unknown = data[data.gene.eq(\"unknown_chrom\") |\n",
        "               data.gene.eq(\"no_gene_found\") |\n",
        "               data.gene.eq(\"gene_unknown\")]\n",
        "\n",
        "unknown = unknown.reset_index(drop = True)\n",
        "\n",
        "for gene, data_gene in data.groupby('gene'):\n",
        "    data_gene\n",
        "\n",
        "data_gene.iloc[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter value that you want data to be greater than (Ratio: HLG / ALL (Whole)): 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IB                           TGTTTTCGTGCTCCTACGACAG\n",
              "gene                                  Cre52.g761647\n",
              "Ratios: HLG / ALL (Whole)                         0\n",
              "RatioType                                   Non-Hit\n",
              "Name: 103055, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn9r9qHiVmbu"
      },
      "source": [
        "**Actual Fisher Exact Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlmSjxKXQD77",
        "outputId": "f04005be-8208-484f-f78d-ef952ebdbd9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bigHit = 0\n",
        "bigNo = 0\n",
        "\n",
        "lastGene = data_gene['gene'].iloc[-1]\n",
        "count = float(input(\"For the total number of counts (hits + non-hits) of a gene, enter a number for cutoff : \"))\n",
        "\n",
        "for gene, data_genie in data.groupby('gene'):\n",
        "    data_genie = data_genie.drop(columns = {'IB', \"Ratios: HLG / ALL (Whole)\"})\n",
        "   \n",
        "    hit = data_genie.loc[data_genie.RatioType == 'Hit', \"RatioType\"].count()\n",
        "    noHit = data_genie.loc[data_genie.RatioType == \"Non-Hit\", \"RatioType\"].count()\n",
        "\n",
        "    bigHit =  bigHit + hit\n",
        "    bigNo = bigNo + noHit\n",
        "    if lastGene in data_genie.values:\n",
        "        sum = pd.DataFrame (\n",
        "            { \n",
        "#                 'Gene': \"  \",\n",
        "                'Hit' : bigHit,\n",
        "                'Non-Hit' : bigNo\n",
        "#                 'Total': bigTotal\n",
        "            }, index = [0]\n",
        "        )\n",
        "\n",
        "#         sum = sum.to_numpy()\n",
        "\n",
        "goaway = pd.DataFrame()\n",
        "biggergoaway = pd.DataFrame()\n",
        "\n",
        "goname = pd.DataFrame()\n",
        "biggergoname = pd.DataFrame()\n",
        "\n",
        "for gene, data_genie in data.groupby('gene'):\n",
        "    data_genie = data_genie.drop(columns = {'IB', \"Ratios: HLG / ALL (Whole)\"})\n",
        "   \n",
        "    hit = data_genie.loc[data_genie.RatioType == 'Hit', \"RatioType\"].count()\n",
        "    noHit = data_genie.loc[data_genie.RatioType == \"Non-Hit\", \"RatioType\"].count()\n",
        "#     total = hit + noHit\n",
        "    \n",
        "    bigHit =  bigHit + hit\n",
        "    bigNo = bigNo + noHit\n",
        "#     bigTotal = bigTotal + total\n",
        "    \n",
        "    genius = pd.DataFrame (\n",
        "        {\n",
        "        'Gene': data_genie.gene.unique()\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    frame = pd.DataFrame ( \n",
        "         {\n",
        "#             'Gene': data_genie.gene.unique(),\n",
        "            'Hit' : hit,\n",
        "            'Non-Hit' : noHit\n",
        "#             'Total' : total\n",
        "        }, index = [0]\n",
        "    )\n",
        "\n",
        "    concat = pd.concat([frame, sum], ignore_index = True)  \n",
        "    concat = concat.to_numpy()\n",
        "    \n",
        "    obs = np.array(concat)\n",
        "    new = pd.DataFrame(obs)\n",
        "\n",
        "    oddsratio, fisher = stats.fisher_exact(new)\n",
        "    \n",
        "    fishy = np.asarray(fisher)\n",
        "    fishy = fishy.reshape(-1, 1)\n",
        "\n",
        "    frame.astype(float)\n",
        "    sum.astype(float)\n",
        "\n",
        "    fsh = pd.DataFrame(data = fishy, columns = [\"p-value\"])\n",
        "    fsh.astype(float)\n",
        "    \n",
        "    oarfish = np.concatenate((frame, sum), axis = 0)\n",
        "    oarfish = pd.DataFrame(data = oarfish, columns = [\"Hit\", \"Non-Hit\"])\n",
        "\n",
        "    anchovy = pd.DataFrame(data = fsh, columns = [\"p-value\"])\n",
        "\n",
        "    bigFish = pd.concat([oarfish, anchovy], ignore_index = True, sort = True)\n",
        "    bigFish = pd.concat([genius, bigFish], axis = 1)\n",
        "\n",
        "    bigFish.loc[bigFish['Hit'] + bigFish['Non-Hit'] < count] = \"Go Away\"\n",
        "\n",
        "    if bigFish.iloc[0, 0] == \"Go Away\":\n",
        "      bigFish.iloc[2, 3] = \"NO\"\n",
        "\n",
        "    goaway = bigFish.iloc[2]\n",
        "    biggergoaway = biggergoaway.append(goaway)\n",
        "\n",
        "    goname = bigFish.iloc[0]\n",
        "    biggergoname = biggergoname.append(goname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For the total number of counts (hits + non-hits) of a gene, enter a number for cutoff : 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4eeDbGBVcEl"
      },
      "source": [
        "away = biggergoaway.drop(columns = [\"Gene\", \"Hit\", \"Non-Hit\"])\n",
        "away = away[away[\"p-value\"] != \"NO\"]\n",
        "away = away.reset_index(drop = True)\n",
        "\n",
        "\n",
        "pen = biggergoname.drop(columns = [\"Hit\", \"Non-Hit\", \"p-value\"])\n",
        "pen = pen[pen[\"Gene\"] != \"Go Away\"]\n",
        "pen = pen.reset_index(drop = True)\n",
        "\n",
        "\n",
        "pen_away = pen.merge(away, left_index = True, right_index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rez3QbLQBXE"
      },
      "source": [
        "#Benjamini-Hochberg Adjustment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLeKkaSVVwsF",
        "outputId": "1cde95a5-7220-4a83-9abb-bceeeffb0451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "penguin = pen_away[~pen_away.Gene.str.contains(\" & \")]\n",
        "penguin = penguin.reset_index(drop = True)\n",
        "\n",
        "bh_num = float(input(\"Enter the value that all adjusted p-values should be less than (0-1): \"))\n",
        "\n",
        "def FDR_adjust_pvalues(case, N=None, method='BH'):\n",
        "    \"\"\" Adjust a list of p-values for false discovery rate using R's stats::p.adjust function.\n",
        "\n",
        "    N and method are passed to R_stats.p_adjust:\n",
        "     - N is the number of comparisons (if left unspecified, defaults to len(pvalue_list), I think)\n",
        "     - method is the name of the adjustment method to use (inherited from R)\n",
        "\n",
        "    Note that this MUST be done after all the p-values are already collected, on the full list of p-values at once:\n",
        "     trying to do it on single p-values, even with adjusted N, will give different results!\n",
        "    \"\"\"\n",
        "    if not method in R_stats.p_adjust_methods:\n",
        "        raise ValueError(\"Unknown method %s - method must be one of (%s)!\"%(method, ', '.join(R_stats.p_adjust_methods)))\n",
        "    if N is None:   return R_stats.p_adjust(FloatVector(case), method=method)\n",
        "    else:           return R_stats.p_adjust(FloatVector(case), method=method, n=N)\n",
        "\n",
        "# example use\n",
        "penguin[\"Adjusted p-value\"] = FDR_adjust_pvalues(penguin['p-value'])\n",
        "\n",
        "penguin.sort_values(by = 'p-value')\n",
        "\n",
        "adelie = penguin.loc[penguin[\"Adjusted p-value\"] < bh_num]\n",
        "\n",
        "display(adelie)\n",
        "\n",
        "#adelie.to_csv(\"Less than 1 p-values.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the value that all adjusted p-values should be less than (0-1): 0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gene</th>\n",
              "      <th>p-value</th>\n",
              "      <th>Adjusted p-value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1093</th>\n",
              "      <td>Cre13.g589400</td>\n",
              "      <td>0.000115968</td>\n",
              "      <td>0.157717</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Gene      p-value  Adjusted p-value\n",
              "1093  Cre13.g589400  0.000115968          0.157717"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}